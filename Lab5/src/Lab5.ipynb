{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 32\n",
    "goal_num_classes = 101\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import applications\n",
    "import copy\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL DATA READED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###Read Goal Data Set\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "ImagesPath=\"D:\\\\SomeData\\\\Caltech101\\\\Images\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "src_num_classes = 101\n",
    "goal_x_train=[]\n",
    "goal_x_test=[]\n",
    "goal_y_train=[]\n",
    "goal_y_test=[]\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_train.append(data)\n",
    "        goal_y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_test.append(data)\n",
    "        goal_y_test.append(np.uint8(i))\n",
    "goal_x_test=np.array(goal_x_test)\n",
    "goal_x_train=np.array(goal_x_train)\n",
    "goal_y_train=to_categorical(goal_y_train, num_classes=src_num_classes)\n",
    "goal_y_test=to_categorical(goal_y_test, num_classes=src_num_classes)\n",
    "print (\"GOAL DATA READED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 314,469\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 22s - loss: 3.3727 - acc: 0.2962 - val_loss: 2.7165 - val_acc: 0.4123\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 16s - loss: 2.2905 - acc: 0.4972 - val_loss: 2.0558 - val_acc: 0.5421\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 16s - loss: 1.7660 - acc: 0.5946 - val_loss: 1.6935 - val_acc: 0.5900\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 16s - loss: 1.4421 - acc: 0.6570 - val_loss: 1.5071 - val_acc: 0.6307\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 16s - loss: 1.2418 - acc: 0.6953 - val_loss: 1.3517 - val_acc: 0.6673\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 16s - loss: 1.1040 - acc: 0.7240 - val_loss: 1.2499 - val_acc: 0.6846\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 16s - loss: 1.0026 - acc: 0.7420 - val_loss: 1.1836 - val_acc: 0.6914\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9098 - acc: 0.7710 - val_loss: 1.1550 - val_acc: 0.7016\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8445 - acc: 0.7819 - val_loss: 1.0922 - val_acc: 0.7235\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7932 - acc: 0.7936 - val_loss: 1.0465 - val_acc: 0.7182\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.7388 - acc: 0.8032 - val_loss: 1.0537 - val_acc: 0.7314\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.6924 - acc: 0.8130 - val_loss: 0.9808 - val_acc: 0.7435\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.6552 - acc: 0.8239 - val_loss: 0.9957 - val_acc: 0.7359\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.6256 - acc: 0.8324 - val_loss: 0.9964 - val_acc: 0.7322\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.5989 - acc: 0.8390 - val_loss: 0.9825 - val_acc: 0.7352\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.5696 - acc: 0.8452 - val_loss: 0.9522 - val_acc: 0.7401\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.5348 - acc: 0.8536 - val_loss: 0.9736 - val_acc: 0.7446\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.5118 - acc: 0.8618 - val_loss: 0.9738 - val_acc: 0.7401\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.4902 - acc: 0.8724 - val_loss: 0.9724 - val_acc: 0.7442\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.4690 - acc: 0.8721 - val_loss: 0.8965 - val_acc: 0.7661\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.4512 - acc: 0.8750 - val_loss: 0.9247 - val_acc: 0.7627\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.4361 - acc: 0.8817 - val_loss: 0.9072 - val_acc: 0.7624\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.4154 - acc: 0.8825 - val_loss: 0.8795 - val_acc: 0.7601\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3994 - acc: 0.8926 - val_loss: 0.9132 - val_acc: 0.7590\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3817 - acc: 0.8964 - val_loss: 0.8862 - val_acc: 0.7661\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3735 - acc: 0.9026 - val_loss: 0.9023 - val_acc: 0.7665\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3506 - acc: 0.9086 - val_loss: 0.9259 - val_acc: 0.7537\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3476 - acc: 0.9074 - val_loss: 0.9224 - val_acc: 0.7593\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3329 - acc: 0.9104 - val_loss: 0.8911 - val_acc: 0.7639\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3249 - acc: 0.9115 - val_loss: 0.8749 - val_acc: 0.7740\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.3040 - acc: 0.9205 - val_loss: 0.9539 - val_acc: 0.7563\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.2951 - acc: 0.9222 - val_loss: 0.8896 - val_acc: 0.7756\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.2838 - acc: 0.9262 - val_loss: 0.9279 - val_acc: 0.7665\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 16s - loss: 0.2753 - acc: 0.9242 - val_loss: 0.9201 - val_acc: 0.7665\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 16s - loss: 0.2689 - acc: 0.9291 - val_loss: 0.8983 - val_acc: 0.7710\n",
      "Time = 570.5404155254364\n"
     ]
    }
   ],
   "source": [
    "###1th Experiment: frozen kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "#froze kernel's weights\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 41s - loss: 4.2562 - acc: 0.1004 - val_loss: 4.2127 - val_acc: 0.1049\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1171 - acc: 0.1409 - val_loss: 4.0753 - val_acc: 0.1660\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.1370 - acc: 0.3133 - val_loss: 3.6365 - val_acc: 0.2252\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 39s - loss: 2.4159 - acc: 0.4409 - val_loss: 2.0324 - val_acc: 0.4885\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 39s - loss: 1.5823 - acc: 0.5999 - val_loss: 1.6282 - val_acc: 0.5786\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 39s - loss: 1.1012 - acc: 0.7063 - val_loss: 1.5648 - val_acc: 0.6300\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.7643 - acc: 0.7833 - val_loss: 1.0361 - val_acc: 0.7280\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.5515 - acc: 0.8423 - val_loss: 0.9754 - val_acc: 0.7476\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.4292 - acc: 0.8716 - val_loss: 0.9741 - val_acc: 0.7627\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.3612 - acc: 0.8951 - val_loss: 1.0189 - val_acc: 0.7586\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.3448 - acc: 0.9008 - val_loss: 1.4363 - val_acc: 0.6858\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.2706 - acc: 0.9184 - val_loss: 1.0141 - val_acc: 0.7937\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 40s - loss: 0.2048 - acc: 0.9401 - val_loss: 1.0857 - val_acc: 0.7605\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1348 - acc: 0.9620 - val_loss: 1.0785 - val_acc: 0.7786\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1457 - acc: 0.9559 - val_loss: 0.8870 - val_acc: 0.8023\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 40s - loss: 0.1219 - acc: 0.9625 - val_loss: 0.9049 - val_acc: 0.8295\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0881 - acc: 0.9744 - val_loss: 1.0174 - val_acc: 0.8080\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0884 - acc: 0.9734 - val_loss: 1.0252 - val_acc: 0.8054\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0751 - acc: 0.9789 - val_loss: 0.8367 - val_acc: 0.8246\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0402 - acc: 0.9892 - val_loss: 1.1289 - val_acc: 0.7944\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0309 - acc: 0.9939 - val_loss: 0.7875 - val_acc: 0.8567\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0248 - acc: 0.9930 - val_loss: 0.7744 - val_acc: 0.8521\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0243 - acc: 0.9930 - val_loss: 0.8993 - val_acc: 0.8336\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0547 - acc: 0.9849 - val_loss: 1.2095 - val_acc: 0.7963\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0595 - acc: 0.9817 - val_loss: 0.9198 - val_acc: 0.8291\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0339 - acc: 0.9902 - val_loss: 1.1574 - val_acc: 0.8121\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0431 - acc: 0.9879 - val_loss: 1.0697 - val_acc: 0.8008\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0433 - acc: 0.9887 - val_loss: 0.7263 - val_acc: 0.8495\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 38s - loss: 0.0092 - acc: 0.9973 - val_loss: 0.8052 - val_acc: 0.8533\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0050 - acc: 0.9995 - val_loss: 0.7277 - val_acc: 0.8612\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 38s - loss: 6.7038e-04 - acc: 0.9998 - val_loss: 0.7247 - val_acc: 0.8665\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.0795e-04 - acc: 0.9998 - val_loss: 0.7374 - val_acc: 0.8668\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 38s - loss: 4.3865e-04 - acc: 0.9997 - val_loss: 0.7413 - val_acc: 0.8668\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1769e-04 - acc: 0.9997 - val_loss: 0.7491 - val_acc: 0.8680\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.0559e-04 - acc: 0.9997 - val_loss: 0.7536 - val_acc: 0.8676\n",
      "Time = 1380.0968787670135\n"
     ]
    }
   ],
   "source": [
    "###2th Experiment: trainable kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.2918 - acc: 0.0938 - val_loss: 4.2115 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1954 - acc: 0.0914 - val_loss: 4.1965 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1264 - acc: 0.1087 - val_loss: 4.2005 - val_acc: 0.0902\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.9407 - acc: 0.1581 - val_loss: 4.2202 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1939 - acc: 0.0886 - val_loss: 4.2142 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 39s - loss: 4.1888 - acc: 0.0943 - val_loss: 4.2009 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.9808 - acc: 0.1540 - val_loss: 3.6922 - val_acc: 0.2290\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.5729 - acc: 0.2378 - val_loss: 3.5018 - val_acc: 0.2648\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.2770 - acc: 0.2934 - val_loss: 3.6913 - val_acc: 0.2757\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 39s - loss: 3.0330 - acc: 0.3470 - val_loss: 3.0815 - val_acc: 0.3470\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 39s - loss: 2.7227 - acc: 0.3940 - val_loss: 2.6918 - val_acc: 0.4074\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 39s - loss: 2.3977 - acc: 0.4532 - val_loss: 2.8521 - val_acc: 0.3916\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 39s - loss: 2.0848 - acc: 0.5050 - val_loss: 2.4272 - val_acc: 0.4538\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 39s - loss: 1.8197 - acc: 0.5609 - val_loss: 2.3109 - val_acc: 0.4930\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 39s - loss: 1.5452 - acc: 0.6163 - val_loss: 2.2565 - val_acc: 0.4734\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 38s - loss: 1.2741 - acc: 0.6708 - val_loss: 2.1693 - val_acc: 0.5104\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 38s - loss: 1.0420 - acc: 0.7280 - val_loss: 2.3113 - val_acc: 0.5145\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 38s - loss: 0.8548 - acc: 0.7765 - val_loss: 2.8998 - val_acc: 0.4787\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 38s - loss: 0.7215 - acc: 0.8063 - val_loss: 2.7694 - val_acc: 0.5281\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.6128 - acc: 0.8359 - val_loss: 2.4158 - val_acc: 0.5130\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.5115 - acc: 0.8604 - val_loss: 2.7475 - val_acc: 0.5081\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.4772 - acc: 0.8699 - val_loss: 2.8975 - val_acc: 0.4979\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.3837 - acc: 0.8974 - val_loss: 3.9071 - val_acc: 0.5104\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.2861 - acc: 0.9223 - val_loss: 3.2537 - val_acc: 0.5353\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.2670 - acc: 0.9298 - val_loss: 3.5896 - val_acc: 0.5243\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1789 - acc: 0.9527 - val_loss: 3.8360 - val_acc: 0.5402\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.2256 - acc: 0.9447 - val_loss: 3.4611 - val_acc: 0.5153\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 38s - loss: 0.1608 - acc: 0.9554 - val_loss: 2.7707 - val_acc: 0.5455\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1499 - acc: 0.9593 - val_loss: 3.8494 - val_acc: 0.5172\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 38s - loss: 0.1354 - acc: 0.9668 - val_loss: 4.1127 - val_acc: 0.5406\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1417 - acc: 0.9658 - val_loss: 3.3586 - val_acc: 0.5228\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.1032 - acc: 0.9759 - val_loss: 3.8326 - val_acc: 0.5470\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0965 - acc: 0.9746 - val_loss: 4.1821 - val_acc: 0.5304\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0960 - acc: 0.9723 - val_loss: 3.8643 - val_acc: 0.5379\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 39s - loss: 0.0928 - acc: 0.9788 - val_loss: 3.4487 - val_acc: 0.5598\n",
      "Time = 1374.5278277397156\n"
     ]
    }
   ],
   "source": [
    "###3th Experiment: just VGG16 struct (don't load pre train weights)\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
