{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 32\n",
    "goal_num_classes = 125\n",
    "src_num_classes = 125\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL DATA READED\n",
      "SRC DATA READED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###Read Goal Data Set\n",
    "\n",
    "ImagesPath=\"D:\\\\SomeData\\\\Caltech101\\\\Images\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "goal_x_train=[]\n",
    "goal_x_test=[]\n",
    "goal_y_train=[]\n",
    "goal_y_test=[]\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_train.append(data)\n",
    "        goal_y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_test.append(data)\n",
    "        goal_y_test.append(np.uint8(i))\n",
    "goal_x_test=np.array(goal_x_test)\n",
    "goal_x_train=np.array(goal_x_train)\n",
    "goal_y_train=to_categorical(goal_y_train, num_classes=src_num_classes)\n",
    "goal_y_test=to_categorical(goal_y_test, num_classes=src_num_classes)\n",
    "print (\"GOAL DATA READED\")\n",
    "\n",
    "\n",
    "###Read SRC Data Set\n",
    "\n",
    "ImagesPath=\"D:\\\\SomeData\\\\256_ObjectCategories\\\\256_ObjectCategories\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "src_x_train=[]\n",
    "src_x_test=[]\n",
    "src_y_train=[]\n",
    "src_y_test=[]\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        src_x_train.append(data)\n",
    "        src_y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        src_x_test.append(data)\n",
    "        src_y_test.append(np.uint8(i))\n",
    "src_x_test=np.array(src_x_test)\n",
    "src_x_train=np.array(src_x_train)\n",
    "src_y_train=to_categorical(src_y_train,num_classes=src_num_classes)\n",
    "src_y_test=to_categorical(src_y_test,num_classes=src_num_classes)\n",
    "print (\"SRC DATA READED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "###Configure TMP Model\n",
    "model_tmp = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_tmp.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=goal_x_train.shape[1:]))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(32, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(64, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Conv2D(128, (5, 5)))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Flatten())\n",
    "model_tmp.add(Dense(512))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Dropout(0.5))\n",
    "model_tmp.add(Dense(goal_num_classes))\n",
    "model_tmp.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "###Configure SRC Model\n",
    "model_src = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_src.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=src_x_train.shape[1:]))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(32, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(Conv2D(64, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(128, (5, 5)))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Flatten())\n",
    "model_src.add(Dense(512))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Dropout(0.5))\n",
    "model_src.add(Dense(src_num_classes))\n",
    "model_src.add(Activation('softmax'))\n",
    "\n",
    "# save init weightts\n",
    "for layer in model_src.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    if (g['name'] == 'dense_1'):\n",
    "        src_init_weight_d1 = copy.deepcopy(h)\n",
    "    if (g['name'] == 'dense_2'):\n",
    "        src_init_weight_d2 = copy.deepcopy(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 125)               64125     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 125)               0         \n",
      "=================================================================\n",
      "Total params: 11,820,445\n",
      "Trainable params: 11,820,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7733 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "7733/7733 [==============================] - 26s - loss: 4.6543 - acc: 0.0325 - val_loss: 4.9828 - val_acc: 0.0053\n",
      "Epoch 2/35\n",
      "7733/7733 [==============================] - 19s - loss: 4.4088 - acc: 0.0639 - val_loss: 5.0223 - val_acc: 0.0091\n",
      "Epoch 3/35\n",
      "7733/7733 [==============================] - 19s - loss: 4.1511 - acc: 0.1124 - val_loss: 5.2348 - val_acc: 0.0057\n",
      "Epoch 4/35\n",
      "7733/7733 [==============================] - 19s - loss: 3.8211 - acc: 0.1632 - val_loss: 5.7484 - val_acc: 0.0102\n",
      "Epoch 5/35\n",
      "7733/7733 [==============================] - 19s - loss: 3.5305 - acc: 0.2082 - val_loss: 6.0384 - val_acc: 0.0087\n",
      "Epoch 6/35\n",
      "7733/7733 [==============================] - 19s - loss: 3.2189 - acc: 0.2642 - val_loss: 6.4316 - val_acc: 0.0117\n",
      "Epoch 7/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.9322 - acc: 0.3149 - val_loss: 6.7861 - val_acc: 0.0106\n",
      "Epoch 8/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.6046 - acc: 0.3720 - val_loss: 7.1015 - val_acc: 0.0113\n",
      "Epoch 9/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.5819 - acc: 0.3745 - val_loss: 7.3754 - val_acc: 0.0162\n",
      "Epoch 10/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.4575 - acc: 0.4029 - val_loss: 7.3965 - val_acc: 0.0192\n",
      "Epoch 11/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3921 - acc: 0.4115 - val_loss: 7.7514 - val_acc: 0.0102\n",
      "Epoch 12/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3711 - acc: 0.4147 - val_loss: 7.6210 - val_acc: 0.0128\n",
      "Epoch 13/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3804 - acc: 0.4254 - val_loss: 7.9915 - val_acc: 0.0143\n",
      "Epoch 14/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3852 - acc: 0.4235 - val_loss: 7.8453 - val_acc: 0.0155\n",
      "Epoch 15/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3813 - acc: 0.4225 - val_loss: 8.1018 - val_acc: 0.0106\n",
      "Epoch 16/35\n",
      "7733/7733 [==============================] - 18s - loss: 2.3723 - acc: 0.4283 - val_loss: 8.2378 - val_acc: 0.0098\n",
      "Epoch 17/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3915 - acc: 0.4308 - val_loss: 8.4636 - val_acc: 0.0087\n",
      "Epoch 18/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.3402 - acc: 0.4311 - val_loss: 8.4138 - val_acc: 0.0091\n",
      "Epoch 19/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.6317 - acc: 0.3847 - val_loss: 8.3041 - val_acc: 0.0079\n",
      "Epoch 20/35\n",
      "7733/7733 [==============================] - 19s - loss: 2.6941 - acc: 0.3776 - val_loss: 8.1048 - val_acc: 0.0091\n",
      "Epoch 21/35\n",
      "7733/7733 [==============================] - 19s - loss: 3.2940 - acc: 0.2983 - val_loss: 8.0678 - val_acc: 0.0128\n",
      "Epoch 22/35\n",
      "7733/7733 [==============================] - 19s - loss: 3.6832 - acc: 0.2500 - val_loss: 7.7490 - val_acc: 0.0060\n",
      "Epoch 23/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.3142 - acc: 0.1062 - val_loss: 5.1361 - val_acc: 0.0045\n",
      "Epoch 24/35\n",
      "7733/7733 [==============================] - 19s - loss: 6.1376 - acc: 0.0097 - val_loss: 5.0827 - val_acc: 0.0057\n",
      "Epoch 25/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.8688 - acc: 0.0115 - val_loss: 5.1297 - val_acc: 0.0068\n",
      "Epoch 26/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.6642 - acc: 0.0115 - val_loss: 5.0854 - val_acc: 0.0053\n",
      "Epoch 27/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.5479 - acc: 0.0111 - val_loss: 5.2189 - val_acc: 0.0045\n",
      "Epoch 28/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.4809 - acc: 0.0110 - val_loss: 5.2657 - val_acc: 0.0102\n",
      "Epoch 29/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.4043 - acc: 0.0116 - val_loss: 5.0098 - val_acc: 0.0079\n",
      "Epoch 30/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.3819 - acc: 0.0123 - val_loss: 4.9620 - val_acc: 0.0083\n",
      "Epoch 31/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.3509 - acc: 0.0118 - val_loss: 5.0153 - val_acc: 0.0094\n",
      "Epoch 32/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7733/7733 [==============================] - 19s - loss: 5.2946 - acc: 0.0149 - val_loss: 5.0159 - val_acc: 0.0030\n",
      "Epoch 33/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.2938 - acc: 0.0124 - val_loss: 4.9729 - val_acc: 0.0102\n",
      "Epoch 34/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.2934 - acc: 0.0125 - val_loss: 5.0431 - val_acc: 0.0038\n",
      "Epoch 35/35\n",
      "7733/7733 [==============================] - 19s - loss: 5.3106 - acc: 0.0113 - val_loss: 4.8333 - val_acc: 0.0049\n",
      "Time = 682.0637037754059\n"
     ]
    }
   ],
   "source": [
    "###1th Experiment\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model_src.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_src.summary())\n",
    "\n",
    "t0=time.time()\n",
    "model_src.fit(src_x_train, src_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configure TMP Model\n",
    "model_tmp = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_tmp.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=goal_x_train.shape[1:]))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(32, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(64, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Conv2D(128, (5, 5)))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Flatten())\n",
    "model_tmp.add(Dense(512))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Dropout(0.5))\n",
    "model_tmp.add(Dense(goal_num_classes))\n",
    "model_tmp.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "###Configure SRC Model\n",
    "model_src = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_src.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=src_x_train.shape[1:]))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(32, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(Conv2D(64, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(128, (5, 5)))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Flatten())\n",
    "model_src.add(Dense(512))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Dropout(0.5))\n",
    "model_src.add(Dense(src_num_classes))\n",
    "model_src.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 125)               64125     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 125)               0         \n",
      "=================================================================\n",
      "Total params: 11,820,445\n",
      "Trainable params: 11,820,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 18s - loss: 4.0131 - acc: 0.1988 - val_loss: 4.5553 - val_acc: 0.1614\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.1250 - acc: 0.3483 - val_loss: 2.8928 - val_acc: 0.3791\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 2.4260 - acc: 0.4686 - val_loss: 2.7519 - val_acc: 0.4157\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.8065 - acc: 0.5802 - val_loss: 2.1087 - val_acc: 0.5258\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.3682 - acc: 0.6606 - val_loss: 2.0445 - val_acc: 0.5541\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.0355 - acc: 0.7320 - val_loss: 2.0376 - val_acc: 0.5556\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7282 - acc: 0.7994 - val_loss: 1.9797 - val_acc: 0.5673\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.5156 - acc: 0.8553 - val_loss: 1.9138 - val_acc: 0.5839\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.3619 - acc: 0.9016 - val_loss: 1.9824 - val_acc: 0.5790\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.2570 - acc: 0.9311 - val_loss: 1.9986 - val_acc: 0.5820\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1966 - acc: 0.9471 - val_loss: 1.9776 - val_acc: 0.5907\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1483 - acc: 0.9638 - val_loss: 2.0070 - val_acc: 0.5949\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1046 - acc: 0.9753 - val_loss: 2.0026 - val_acc: 0.5979\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0923 - acc: 0.9794 - val_loss: 2.0225 - val_acc: 0.6024\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0633 - acc: 0.9874 - val_loss: 1.9966 - val_acc: 0.6020\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0445 - acc: 0.9924 - val_loss: 2.0296 - val_acc: 0.6035\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0478 - acc: 0.9902 - val_loss: 2.0028 - val_acc: 0.6051\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0336 - acc: 0.9954 - val_loss: 2.0107 - val_acc: 0.6122\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0329 - acc: 0.9947 - val_loss: 2.0193 - val_acc: 0.6156\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0322 - acc: 0.9934 - val_loss: 2.0381 - val_acc: 0.6066\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0258 - acc: 0.9949 - val_loss: 2.0211 - val_acc: 0.6126\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0211 - acc: 0.9963 - val_loss: 2.0024 - val_acc: 0.6134\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0179 - acc: 0.9982 - val_loss: 2.0324 - val_acc: 0.6134\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0163 - acc: 0.9980 - val_loss: 2.0240 - val_acc: 0.6152\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0176 - acc: 0.9967 - val_loss: 2.0241 - val_acc: 0.6130\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0150 - acc: 0.9977 - val_loss: 2.0339 - val_acc: 0.6183\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0142 - acc: 0.9982 - val_loss: 2.0434 - val_acc: 0.6194\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0122 - acc: 0.9985 - val_loss: 2.0422 - val_acc: 0.6167\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0098 - acc: 0.9990 - val_loss: 2.0385 - val_acc: 0.6145\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0105 - acc: 0.9990 - val_loss: 2.0365 - val_acc: 0.6258\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0097 - acc: 0.9993 - val_loss: 2.0270 - val_acc: 0.6224\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0096 - acc: 0.9992 - val_loss: 2.0159 - val_acc: 0.6198\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0074 - acc: 0.9992 - val_loss: 2.0325 - val_acc: 0.6179\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0076 - acc: 0.9993 - val_loss: 2.0298 - val_acc: 0.6213\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0065 - acc: 0.9998 - val_loss: 2.0478 - val_acc: 0.6209\n",
      "Time = 549.137414932251\n"
     ]
    }
   ],
   "source": [
    "###2th Experiment\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model_src.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_src.summary())\n",
    "\n",
    "t0=time.time()\n",
    "model_src.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configure TMP Model\n",
    "model_tmp = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_tmp.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=goal_x_train.shape[1:]))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(32, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(64, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Conv2D(128, (5, 5)))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Flatten())\n",
    "model_tmp.add(Dense(512))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Dropout(0.5))\n",
    "model_tmp.add(Dense(goal_num_classes))\n",
    "model_tmp.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "###Configure SRC Model\n",
    "model_src = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_src.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=src_x_train.shape[1:]))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(32, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(Conv2D(64, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(128, (5, 5)))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Flatten())\n",
    "model_src.add(Dense(512))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Dropout(0.5))\n",
    "model_src.add(Dense(src_num_classes))\n",
    "model_src.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 125)               64125     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 125)               0         \n",
      "=================================================================\n",
      "Total params: 11,820,445\n",
      "Trainable params: 11,820,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/35\n",
      "7733/7733 [==============================] - 20s - loss: 4.7114 - acc: 0.0212    \n",
      "Epoch 2/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.6362 - acc: 0.0264    \n",
      "Epoch 3/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.4790 - acc: 0.0552    \n",
      "Epoch 4/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.1289 - acc: 0.1090    \n",
      "Epoch 5/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.6600 - acc: 0.1830    \n",
      "Epoch 6/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.2779 - acc: 0.2541    \n",
      "Epoch 7/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.8092 - acc: 0.3313    - ETA\n",
      "Epoch 8/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.4332 - acc: 0.3976    \n",
      "Epoch 9/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.1654 - acc: 0.4523    \n",
      "Epoch 10/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.9598 - acc: 0.4933    \n",
      "Epoch 11/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.7957 - acc: 0.5284    \n",
      "Epoch 12/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.6858 - acc: 0.5502    \n",
      "Epoch 13/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.7438 - acc: 0.5408    \n",
      "Epoch 14/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.7151 - acc: 0.5443    \n",
      "Epoch 15/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.7786 - acc: 0.5390    \n",
      "Epoch 16/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.9134 - acc: 0.5107    \n",
      "Epoch 17/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.9563 - acc: 0.4981    \n",
      "Epoch 18/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.3100 - acc: 0.4482    \n",
      "Epoch 19/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.6143 - acc: 0.3983    \n",
      "Epoch 20/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.7012 - acc: 0.3714    \n",
      "Epoch 21/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.2903 - acc: 0.3008    \n",
      "Epoch 22/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.0665 - acc: 0.2101    \n",
      "Epoch 23/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.6432 - acc: 0.1373    \n",
      "Epoch 24/35\n",
      "7733/7733 [==============================] - 17s - loss: 6.2657 - acc: 0.0200    \n",
      "Epoch 25/35\n",
      "7733/7733 [==============================] - 17s - loss: 6.0368 - acc: 0.0132    - ETA: 1s - lo\n",
      "Epoch 26/35\n",
      "7733/7733 [==============================] - 16s - loss: 5.7282 - acc: 0.0128    \n",
      "Epoch 27/35\n",
      "7733/7733 [==============================] - 16s - loss: 5.6079 - acc: 0.0111    \n",
      "Epoch 28/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.4582 - acc: 0.0158    \n",
      "Epoch 29/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.3873 - acc: 0.0164    \n",
      "Epoch 30/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.3657 - acc: 0.0167    \n",
      "Epoch 31/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.3341 - acc: 0.0172    \n",
      "Epoch 32/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.2901 - acc: 0.0169    \n",
      "Epoch 33/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.2809 - acc: 0.0175    \n",
      "Epoch 34/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.2683 - acc: 0.0215    \n",
      "Epoch 35/35\n",
      "7733/7733 [==============================] - 17s - loss: 5.2110 - acc: 0.0216    \n",
      "Time = 606.0236511230469\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9537 - acc: 0.0591 - val_loss: 4.5673 - val_acc: 0.0902\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8871 - acc: 0.0670 - val_loss: 4.9491 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9016 - acc: 0.0599 - val_loss: 4.6431 - val_acc: 0.0494\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8900 - acc: 0.0662 - val_loss: 4.3941 - val_acc: 0.1064\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9059 - acc: 0.0589 - val_loss: 4.4867 - val_acc: 0.0321\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8780 - acc: 0.0644 - val_loss: 4.5290 - val_acc: 0.0924\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8732 - acc: 0.0655 - val_loss: 4.4681 - val_acc: 0.0962\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.7862 - acc: 0.0833 - val_loss: 4.2630 - val_acc: 0.1294\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8615 - acc: 0.0745 - val_loss: 4.4345 - val_acc: 0.0585\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8967 - acc: 0.0646 - val_loss: 4.4404 - val_acc: 0.1000\n",
      "Epoch 11/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 15s - loss: 4.8577 - acc: 0.0637 - val_loss: 4.5842 - val_acc: 0.0947\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8110 - acc: 0.0750 - val_loss: 4.2921 - val_acc: 0.1769\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8108 - acc: 0.0850 - val_loss: 4.2676 - val_acc: 0.1479\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.7581 - acc: 0.0954 - val_loss: 4.1598 - val_acc: 0.1392\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.7090 - acc: 0.1055 - val_loss: 4.2546 - val_acc: 0.1241\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.5877 - acc: 0.1349 - val_loss: 4.0842 - val_acc: 0.1384\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.3346 - acc: 0.1739 - val_loss: 4.3341 - val_acc: 0.1124\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0325 - acc: 0.0604 - val_loss: 4.4651 - val_acc: 0.1181\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.6793 - acc: 0.1075 - val_loss: 3.7117 - val_acc: 0.2346\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.7746 - acc: 0.2499 - val_loss: 3.0818 - val_acc: 0.3361\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.5769 - acc: 0.2818 - val_loss: 2.9650 - val_acc: 0.3791\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.2926 - acc: 0.3219 - val_loss: 2.8587 - val_acc: 0.3882\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.3927 - acc: 0.3024 - val_loss: 2.8143 - val_acc: 0.4021\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.8511 - acc: 0.2471 - val_loss: 3.7631 - val_acc: 0.2297\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.3713 - acc: 0.1767 - val_loss: 4.4087 - val_acc: 0.1015\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.1994 - acc: 0.0541 - val_loss: 4.5379 - val_acc: 0.0905\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0696 - acc: 0.0579 - val_loss: 4.5831 - val_acc: 0.0132\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0305 - acc: 0.0597 - val_loss: 4.4230 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9809 - acc: 0.0548 - val_loss: 4.7603 - val_acc: 0.0494\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9620 - acc: 0.0619 - val_loss: 4.5170 - val_acc: 0.0905\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9349 - acc: 0.0617 - val_loss: 4.7725 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9280 - acc: 0.0599 - val_loss: 4.5129 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9311 - acc: 0.0599 - val_loss: 4.6410 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9156 - acc: 0.0659 - val_loss: 4.5526 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9250 - acc: 0.0604 - val_loss: 4.5545 - val_acc: 0.0905\n",
      "Time = 543.9308857917786\n"
     ]
    }
   ],
   "source": [
    "###3th Experiment\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model_src.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_src.summary())\n",
    "\n",
    "t0=time.time()\n",
    "model_src.fit(src_x_train, src_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "for layer in model_src.layers:\n",
    "    g=layer.get_config()\n",
    "    if ((g['name'] != 'dense_2')&(g['name'] != 'dense_2')):\n",
    "        layer.trainable = False\n",
    "\n",
    "t0=time.time()\n",
    "model_src.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Configure TMP Model\n",
    "model_tmp = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_tmp.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=goal_x_train.shape[1:]))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(32, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(Conv2D(64, (3, 3)))\n",
    "model_tmp.add(Activation('relu'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Conv2D(128, (5, 5)))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_tmp.add(Dropout(0.25))\n",
    "\n",
    "model_tmp.add(Flatten())\n",
    "model_tmp.add(Dense(512))\n",
    "model_tmp.add(Activation('tanh'))\n",
    "model_tmp.add(Dropout(0.5))\n",
    "model_tmp.add(Dense(goal_num_classes))\n",
    "model_tmp.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "###Configure SRC Model\n",
    "model_src = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model_src.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=src_x_train.shape[1:]))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(32, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(Conv2D(64, (3, 3)))\n",
    "model_src.add(Activation('relu'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Conv2D(128, (5, 5)))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_src.add(Dropout(0.25))\n",
    "\n",
    "model_src.add(Flatten())\n",
    "model_src.add(Dense(512))\n",
    "model_src.add(Activation('tanh'))\n",
    "model_src.add(Dropout(0.5))\n",
    "model_src.add(Dense(src_num_classes))\n",
    "model_src.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 125)               64125     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 125)               0         \n",
      "=================================================================\n",
      "Total params: 11,820,445\n",
      "Trainable params: 11,820,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.7127 - acc: 0.0217    \n",
      "Epoch 2/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.6573 - acc: 0.0256    \n",
      "Epoch 3/35\n",
      "7733/7733 [==============================] - 17s - loss: 4.4280 - acc: 0.0586    \n",
      "Epoch 4/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.9872 - acc: 0.1235    \n",
      "Epoch 5/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.5639 - acc: 0.1924    \n",
      "Epoch 6/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.0832 - acc: 0.2734    \n",
      "Epoch 7/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.5553 - acc: 0.3761    \n",
      "Epoch 8/35\n",
      "7733/7733 [==============================] - 17s - loss: 2.0287 - acc: 0.4818    \n",
      "Epoch 9/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.5697 - acc: 0.5841    \n",
      "Epoch 10/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.2051 - acc: 0.6666    \n",
      "Epoch 11/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.9649 - acc: 0.7280    \n",
      "Epoch 12/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.7520 - acc: 0.7848    \n",
      "Epoch 13/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.6456 - acc: 0.8143    \n",
      "Epoch 14/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.5433 - acc: 0.8412    \n",
      "Epoch 15/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.4755 - acc: 0.8597    \n",
      "Epoch 16/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.4337 - acc: 0.8702    \n",
      "Epoch 17/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3641 - acc: 0.8932    \n",
      "Epoch 18/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3231 - acc: 0.9007    \n",
      "Epoch 19/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3411 - acc: 0.9012    \n",
      "Epoch 20/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3266 - acc: 0.8982    \n",
      "Epoch 21/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.2734 - acc: 0.9171    \n",
      "Epoch 22/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3221 - acc: 0.9044    \n",
      "Epoch 23/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3066 - acc: 0.9040    \n",
      "Epoch 24/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3177 - acc: 0.9009    \n",
      "Epoch 25/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3517 - acc: 0.8959    \n",
      "Epoch 26/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3967 - acc: 0.8812    \n",
      "Epoch 27/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.3996 - acc: 0.8826    \n",
      "Epoch 28/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.4292 - acc: 0.8724    \n",
      "Epoch 29/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.5563 - acc: 0.8365    - ETA: 1s - loss: \n",
      "Epoch 30/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.7042 - acc: 0.7957    \n",
      "Epoch 31/35\n",
      "7733/7733 [==============================] - 17s - loss: 0.9530 - acc: 0.7308    \n",
      "Epoch 32/35\n",
      "7733/7733 [==============================] - 17s - loss: 1.3360 - acc: 0.6524    \n",
      "Epoch 33/35\n",
      "7733/7733 [==============================] - 17s - loss: 3.1162 - acc: 0.3854    \n",
      "Epoch 34/35\n",
      "7733/7733 [==============================] - 17s - loss: 6.9339 - acc: 0.0403    \n",
      "Epoch 35/35\n",
      "7733/7733 [==============================] - 17s - loss: 6.9098 - acc: 0.0114    \n",
      "Time = 601.6273438930511\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 16s - loss: 5.9657 - acc: 0.0405 - val_loss: 4.8263 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.6446 - acc: 0.0425 - val_loss: 4.6345 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.4557 - acc: 0.0441 - val_loss: 4.5800 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.3303 - acc: 0.0491 - val_loss: 4.5027 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.2320 - acc: 0.0568 - val_loss: 4.5346 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.1907 - acc: 0.0516 - val_loss: 4.7263 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.1104 - acc: 0.0558 - val_loss: 4.7006 - val_acc: 0.0494\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0711 - acc: 0.0539 - val_loss: 4.7648 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0409 - acc: 0.0553 - val_loss: 4.6720 - val_acc: 0.0494\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0042 - acc: 0.0568 - val_loss: 4.6380 - val_acc: 0.0905\n",
      "Epoch 11/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 15s - loss: 4.9919 - acc: 0.0599 - val_loss: 4.4318 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9632 - acc: 0.0554 - val_loss: 4.4522 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9252 - acc: 0.0573 - val_loss: 4.7592 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9553 - acc: 0.0632 - val_loss: 4.5458 - val_acc: 0.0045\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9575 - acc: 0.0549 - val_loss: 4.5023 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9708 - acc: 0.0569 - val_loss: 4.4552 - val_acc: 0.0272\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9098 - acc: 0.0587 - val_loss: 4.7682 - val_acc: 0.0494\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9244 - acc: 0.0539 - val_loss: 4.5109 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9066 - acc: 0.0573 - val_loss: 4.4433 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9152 - acc: 0.0636 - val_loss: 4.4698 - val_acc: 0.0905\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9006 - acc: 0.0601 - val_loss: 4.9818 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9044 - acc: 0.0611 - val_loss: 4.6771 - val_acc: 0.0494\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9373 - acc: 0.0556 - val_loss: 4.5743 - val_acc: 0.0075\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9094 - acc: 0.0655 - val_loss: 4.5802 - val_acc: 0.0494\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9230 - acc: 0.0617 - val_loss: 4.5266 - val_acc: 0.0494\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9112 - acc: 0.0597 - val_loss: 4.7569 - val_acc: 0.0494\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9207 - acc: 0.0631 - val_loss: 4.5917 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8995 - acc: 0.0644 - val_loss: 4.6093 - val_acc: 0.0494\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9112 - acc: 0.0581 - val_loss: 4.6048 - val_acc: 0.0147\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9019 - acc: 0.0617 - val_loss: 4.5086 - val_acc: 0.0494\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9217 - acc: 0.0624 - val_loss: 4.4706 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8946 - acc: 0.0609 - val_loss: 4.8872 - val_acc: 0.0494\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9398 - acc: 0.0611 - val_loss: 4.6829 - val_acc: 0.0226\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9049 - acc: 0.0597 - val_loss: 5.0708 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8982 - acc: 0.0564 - val_loss: 4.5904 - val_acc: 0.0905\n",
      "Time = 545.3642346858978\n"
     ]
    }
   ],
   "source": [
    "###4th Experiment\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "for layer in model_src.layers:\n",
    "    layer.trainable = True\n",
    "model_src.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_src.summary())\n",
    "\n",
    "t0=time.time()\n",
    "model_src.fit(src_x_train, src_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "weights = model_src.get_weights()\n",
    "#move weights from src to tmp model\n",
    "\n",
    "model_tmp.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model_tmp.set_weights(weights)\n",
    "\n",
    "t0=time.time()\n",
    "model_tmp.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
